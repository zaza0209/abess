
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_gallery\plot_CoxRegression.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_gallery_plot_CoxRegression.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_gallery_plot_CoxRegression.py:


Cox Regression
=============================

.. GENERATED FROM PYTHON SOURCE LINES 6-51

Cox Proportional Hazrds Regression
----------------------------------------
Cox Proportional Hazrds (CoxPH) regression is to describe the survival according to several corvariates. The difference between CoxPH regression and Kaplan-Meier curves or the logrank tests is that the latter only focus on modeling the survival according to one factor (categorical predictor is best) while the former is able to take into consideration any covariates simultaneouly, regardless of whether they're quantitatrive or categorical. The model is as follow:

.. math::
  h(t) = h_0(t)\exp(\eta).


where,

- :math:`\eta = x\beta.`
- :math:`t` is the survival time.
- :math:`h(t)` is the hazard function which evaluate the risk of dying at time :math:`t`.
- :math:`h_0(t)` is called the baseline hazard. It describes value of the hazard if all the predictors are zero.
- :math:`beta` measures the impact of covariates.


Consider two case :math:`i` and :math:`i'` that have different x values. Their hazard function can be simply written as follow

.. math::
  h_i(t) = h_0(t)\exp(\eta_i) = h_0(t)\exp(x_i\beta),


and

.. math::
  h_{i'}(t) = h_0(t)\exp(\eta_{i'}) = h_0(t)\exp(x_{i'}\beta).


The hazard ratio for these two cases is

.. math::
  \frac{h_i(t)}{h_{i'}(t)} & = \frac{h_0(t)\exp(\eta_i)}{h_0(t)\exp(\eta_{i'})} \\
                           & = \frac{\exp(\eta_i)}{\exp(\eta_{i'})},



which is independent of time.

Real Data Example (Lung Cancer Dataset)
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
We are going to apply best subset selection to the NCCTG Lung Cancer Dataset from [https://www.kaggle.com/ukveteran/ncctg-lung-cancer-data](https://www.kaggle.com/ukveteran/ncctg-lung-cancer-data). 
This dataset consists of survival informatoin of patients with advanced lung cancer from the North Central Cancer Treatment Group. The proportional hazards model allows the analysis of survival data by regression modeling. Linearity is assumed on the log scale of the hazard. The hazard ratio in Cox proportional hazard model is assumed constant. 

First, we load the data.

.. GENERATED FROM PYTHON SOURCE LINES 51-58

.. code-block:: default


    import pandas as pd 

    data = pd.read_csv('cancer.csv')
    data = data.drop(data.columns[[0, 1]], axis = 1)
    print(data.head())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

       time  status  age  sex  ph.ecog  ph.karno  pat.karno  meal.cal  wt.loss
    0   306       2   74    1      1.0      90.0      100.0    1175.0      NaN
    1   455       2   68    1      0.0      90.0       90.0    1225.0     15.0
    2  1010       1   56    1      0.0      90.0       90.0       NaN     15.0
    3   210       2   57    1      1.0      90.0       60.0    1150.0     11.0
    4   883       2   60    1      0.0     100.0       90.0       NaN      0.0




.. GENERATED FROM PYTHON SOURCE LINES 59-60

Then we remove the rows containing any missing data. After that, we have a total of 168 observations.

.. GENERATED FROM PYTHON SOURCE LINES 60-64

.. code-block:: default


    data = data.dropna()
    print(data.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (168, 9)




.. GENERATED FROM PYTHON SOURCE LINES 65-66

Then we change the factors `ph.ecog` into dummy variables:

.. GENERATED FROM PYTHON SOURCE LINES 66-72

.. code-block:: default


    data['ph.ecog'] = data['ph.ecog'].astype("category")
    data = pd.get_dummies(data)
    data = data.drop('ph.ecog_0.0', axis = 1)
    print(data.head())





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

       time  status  age  sex  ph.karno  pat.karno  meal.cal  wt.loss  ph.ecog_1.0  ph.ecog_2.0  ph.ecog_3.0
    1   455       2   68    1      90.0       90.0    1225.0     15.0            0            0            0
    3   210       2   57    1      90.0       60.0    1150.0     11.0            1            0            0
    5  1022       1   74    1      50.0       80.0     513.0      0.0            1            0            0
    6   310       2   68    2      70.0       60.0     384.0     10.0            0            1            0
    7   361       2   71    2      60.0       80.0     538.0      1.0            0            1            0




.. GENERATED FROM PYTHON SOURCE LINES 73-74

We split the dataset into a training set and a test set. The model is going to be built on the training set and later we will test the model performance on the test set.

.. GENERATED FROM PYTHON SOURCE LINES 74-85

.. code-block:: default


    import numpy as np
    np.random.seed(0)

    ind = np.linspace(1, 168, 168) <= round(168*2/3)
    train = np.array(data[ind])
    test = np.array(data[~ind])

    print('train size: ', train.shape[0])
    print('test size:', test.shape[0])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    train size:  112
    test size: 56




.. GENERATED FROM PYTHON SOURCE LINES 86-91

Model Fitting
""""""""""""""""""""""""""""""
The `CoxPHSurvivalAnalysis()` function in the `abess` package allows you to perform best subset selection in a highly efficient way. 

By default, the function implements the abess algorithm with the support size (sparsity level) changing from 0 to :math:`\min\{p,n/log(n)p \}` and the best support size is determined by EBIC. You can change the tunging criterion by specifying the argument `ic_type` and the support size by `support_size`. The available tuning criterion now are gic, aic, bic, ebic. Here we give an example.

.. GENERATED FROM PYTHON SOURCE LINES 91-98

.. code-block:: default




    from abess import CoxPHSurvivalAnalysis
    model = CoxPHSurvivalAnalysis(ic_type = 'gic')
    model.fit(train[:, 2:], train[:, :2])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    CoxPHSurvivalAnalysis(always_select=[], ic_type='gic')



.. GENERATED FROM PYTHON SOURCE LINES 99-100

After fitting, the coefficients are stored in `model.coef_`, and the non-zero values indicate the variables used in our model.

.. GENERATED FROM PYTHON SOURCE LINES 100-104

.. code-block:: default



    print(model.coef_)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [ 0.         -0.379564    0.02248522  0.          0.          0.
      0.43729712  1.42127851  2.42095755]




.. GENERATED FROM PYTHON SOURCE LINES 105-106

This result shows that 4 variables (the 2nd, 3rd, 7th, 8th, 9th) are chosen into the Cox model. Then a further analysis can be based on them. 

.. GENERATED FROM PYTHON SOURCE LINES 108-113

More on the results
""""""""""""""""""""""""""""""
Hold on, we arenâ€™t finished yet. After get the estimator, we can further do more exploring work. For example, you can use some generic steps to quickly draw some information of those estimators.

Simply fix the `support_size` in different level, you can plot a path of coefficients like: 

.. GENERATED FROM PYTHON SOURCE LINES 113-134

.. code-block:: default




    import matplotlib.pyplot as plt

    coef = np.zeros((10, 9))
    ic = np.zeros(10)
    for s in range(10):
        model = CoxPHSurvivalAnalysis(support_size = s, ic_type = 'gic')
        model.fit(train[:, 2:], train[:, :2])
        coef[s, :] = model.coef_
        ic[s] = model.ic_

    for i in range(9):
        plt.plot(coef[:, i], label = i)

    plt.xlabel('support_size')
    plt.ylabel('coefficients')
    plt.legend()
    plt.show()




.. image-sg:: /auto_gallery/images/sphx_glr_plot_CoxRegression_001.png
   :alt: plot CoxRegression
   :srcset: /auto_gallery/images/sphx_glr_plot_CoxRegression_001.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 135-136

Or a view of decreasing of information criterion:

.. GENERATED FROM PYTHON SOURCE LINES 136-142

.. code-block:: default


    plt.plot(ic, 'o-')
    plt.xlabel('support_size')
    plt.ylabel('GIC')
    plt.show()




.. image-sg:: /auto_gallery/images/sphx_glr_plot_CoxRegression_002.png
   :alt: plot CoxRegression
   :srcset: /auto_gallery/images/sphx_glr_plot_CoxRegression_002.png
   :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 143-146

Prediction is allowed for all the estimated model. Just call `predict()` function under the model you are interested in. The values it return are :math:`\exp(\eta)=\exp(x\beta)`, which is part of Cox PH hazard function.

Here he give the prediction on the `test` data.

.. GENERATED FROM PYTHON SOURCE LINES 146-150

.. code-block:: default


    pred = model.predict(test[:, 2:])
    print(pred)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [11.0015887  11.97954111  8.11705612  3.32130081  2.9957487   3.23167938
      5.88030263  8.83474265  6.94981468  2.79778448  4.80124013  8.32868839
      6.18472356  7.36597245  2.79540785  7.07729092  3.57284073  6.95551265
      3.59051464  8.73668805  3.51029827  4.28617052  5.21830511  5.11465146
      2.92670651  2.31996184  7.04845409  4.30246362  7.14805341  3.83570919
      6.27832924  6.54442227  8.39353611  5.41713824  4.17823079  4.01469621
      8.99693705  3.98562593  3.9922459   2.79743549  3.47347931  4.40471703
      6.77413094  4.33542254  6.62834299  9.99006885  8.1177072  20.28383502
     14.67346807  2.27915833  5.78151822  4.31221688  3.25950636  6.99318596
      7.4368521   3.86339324]




.. GENERATED FROM PYTHON SOURCE LINES 151-152

With these predictions, we can compute the hazard ratio between every two observations (by deviding their values). Or, we can also compute the C-Index for our model, i.e., the probability that, for a pair of randomly chosen comparable samples, the sample with the higher risk prediction will experience an event before the other sample or belong to a higher binary class. 

.. GENERATED FROM PYTHON SOURCE LINES 152-157

.. code-block:: default


    from sksurv.metrics import concordance_index_censored
    cindex = concordance_index_censored(test[:, 1] == 2, test[:, 0], pred)
    print(cindex[0])





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    0.6839080459770115




.. GENERATED FROM PYTHON SOURCE LINES 158-159

On this dataset, the C-index is about 0.68.

.. GENERATED FROM PYTHON SOURCE LINES 161-164

R tutorial
-------------------------
For R tutorial, please view [https://abess-team.github.io/abess/articles/v05-coxreg.html](https://abess-team.github.io/abess/articles/v05-coxreg.html).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  3.604 seconds)


.. _sphx_glr_download_auto_gallery_plot_CoxRegression.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: plot_CoxRegression.py <plot_CoxRegression.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: plot_CoxRegression.ipynb <plot_CoxRegression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
