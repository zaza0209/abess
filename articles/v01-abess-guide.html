<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Quick start for `abess`: Linear regression â€¢ abess</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Quick start for `abess`: Linear regression">
<meta property="og:description" content="abess">
<meta property="og:image" content="/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">abess</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/v01-abess-guide.html">Quick start for `abess`: Linear regression</a>
    </li>
    <li>
      <a href="../articles/v03-classification.html">Classification: Logistic Regression and Multinomial Extension</a>
    </li>
    <li>
      <a href="../articles/v04-poissonregression.html">Poisson Regression</a>
    </li>
    <li>
      <a href="../articles/v05-coxreg.html">Best Subset Selection for Censored Response</a>
    </li>
    <li>
      <a href="../articles/v06-MultiTaskLearning.html">Multi-Response Linear Regression</a>
    </li>
    <li>
      <a href="../articles/v07-advancedFeatures.html">Advanced Features</a>
    </li>
    <li>
      <a href="../articles/v08-sPCA.html">Principal component analysis</a>
    </li>
    <li>
      <a href="../articles/v09-fasterSetting.html">Tips for faster computation</a>
    </li>
    <li>
      <a href="../articles/v10-algorithm.html">ABESS algorithm: details</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/abess-team/abess/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="v01-abess-guide_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Quick start for <code>abess</code>: Linear regression</h1>
                        <h4 class="author">Jin Zhu</h4>
            
      
      <small class="dont-index">Source: <a href="https://github.com/abess-team/abess/tree/master/R-package/../vignettes/v01-abess-guide.Rmd"><code>../vignettes/v01-abess-guide.Rmd</code></a></small>
      <div class="hidden name"><code>v01-abess-guide.Rmd</code></div>

    </div>

    
    
<div id="briey-introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#briey-introduction" class="anchor"></a>Briey introduction</h2>
<p>The R package <code>abess</code> implement a polynomial algorithm in the <a href="https://www.pnas.org/content/117/52/33117"></a> for best-subset selection problem: <span class="math display">\[\min_{\beta \in \mathbb{R}^p} \frac{1}{2n} \| y - X\beta\|_2^2, \text{ subject to } \|\beta\|_0 \leq s,\]</span> where <span class="math inline">\(\| \cdot \|_2\)</span> is the <span class="math inline">\(\ell_2\)</span> norm, <span class="math inline">\(\|\beta\|_0=\sum_{i=1}^pI( \beta_i\neq 0)\)</span> is the <span class="math inline">\(\ell_0\)</span> norm of <span class="math inline">\(\beta\)</span>, and the sparsity level <span class="math inline">\(s\)</span> is usually an unknown non-negative integer. Next, we present an example to show how to use the <strong>abess</strong> package to solve a simple problem.</p>
</div>
<div id="quick-example" class="section level2">
<h2 class="hasAnchor">
<a href="#quick-example" class="anchor"></a>Quick example</h2>
<div id="fixed-support-size-best-subset-selection" class="section level3">
<h3 class="hasAnchor">
<a href="#fixed-support-size-best-subset-selection" class="anchor"></a>Fixed support size best subset selection</h3>
<p>We generate a design matrix <span class="math inline">\(X\)</span> containing 300 observation and each observation has 1000 predictors. The response variable <span class="math inline">\(y\)</span> is linearly related to the first, second, and fifth predictors in <span class="math inline">\(X\)</span>: <span class="math display">\[y = 3X_1 + 1.5X_2 + 2X_5 + \epsilon,\]</span> where <span class="math inline">\(\epsilon\)</span> is a standard normal random variable.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/abess-team/abess">abess</a></span><span class="op">)</span>
<span class="va">synthetic_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/generate.data.html">generate.data</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">300</span>, p <span class="op">=</span> <span class="fl">1000</span>, 
                                beta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">1.5</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">2</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">995</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">synthetic_data</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<pre><code>## [1]  300 1000</code></pre>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">synthetic_data</span><span class="op">[[</span><span class="st">"y"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<pre><code>##           [,1]
## [1,] -4.063922
## [2,]  3.855246
## [3,] -3.041391
## [4,] -1.081257
## [5,]  4.986772
## [6,]  4.470901</code></pre>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind.data.frame</a></span><span class="op">(</span><span class="st">"y"</span> <span class="op">=</span> <span class="va">synthetic_data</span><span class="op">[[</span><span class="st">"y"</span><span class="op">]</span><span class="op">]</span>, 
                        <span class="va">synthetic_data</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<p>Then, we use the main function <code>abess</code> in the package to fit this dataset. By setting the arguments <code>support.size = s</code>, <code>abess</code> function conducts <strong>Algorithm 1</strong> in the <a href="https://www.pnas.org/content/117/52/33117"></a> for best-subset selection with a sparsity level <code>s</code>. In our example, we set the options: <code>support.size = 3</code>, and we run <strong>Algorithm 1</strong> with the following command:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.default.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span>, support.size <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></code></pre></div>
<p>The output of <code>abess</code> comprises the selected best model:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">abess_fit</span>, sparse <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>##                       3
## (intercept) -0.01802179
## x1           2.96418205
## x2           1.45090693
## x3           0.00000000
## x4           0.00000000
## x5           1.90592036</code></pre>
<p>The best modelâ€™s support set is identical to the ground truth, and the coefficient estimation is the same as the oracle estimator given by <code>lm</code> function:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">5</span><span class="op">)</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ ., data = dat[, c(1, c(1, 2, 5) + 1)])
## 
## Coefficients:
## (Intercept)           x1           x2           x5  
##    -0.01802      2.96418      1.45091      1.90592</code></pre>
<!-- Users could `print`, `summary` or `predict` this bestmodel object just like working with classical regression modeling. This would be helpful for data scientists who are familiar with `lm` functions in R. -->
</div>
<div id="adaptive-best-subset-selection" class="section level3">
<h3 class="hasAnchor">
<a href="#adaptive-best-subset-selection" class="anchor"></a>Adaptive best subset selection</h3>
<p>Imaging we are unknown about the true sparsity level in real world data, and thus, we need to determine the most proper one. The <strong>Algorithm 3</strong> in the <a href="https://www.pnas.org/content/117/52/33117"></a> is designed for this scenario. <code>abess</code> is capable of performing this algorithm:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.default.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span></code></pre></div>
<p>The output of <code>abess</code> also comprises the selected best model:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_size</span> <span class="op">&lt;-</span> <span class="va">abess_fit</span><span class="op">[[</span><span class="st">"best.size"</span><span class="op">]</span><span class="op">]</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">best_size</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 3</code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">abess_fit</span>, support.size <span class="op">=</span> <span class="va">best_size</span>, sparse <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>##                       3
## (intercept) -0.01802179
## x1           2.96418205
## x2           1.45090693
## x3           0.00000000
## x4           0.00000000
## x5           1.90592036</code></pre>
<p>The output model accurately detect the true model size, which implies the <strong>Algorithm 3</strong> efficiently find both the optimal sparsity level and true effective predictors.</p>
</div>
</div>
<div id="real-data-example" class="section level2">
<h2 class="hasAnchor">
<a href="#real-data-example" class="anchor"></a>Real data example</h2>
<div id="hitters-dataset" class="section level3">
<h3 class="hasAnchor">
<a href="#hitters-dataset" class="anchor"></a>Hitters Dataset</h3>
<p>In this tutorial, we are going to demonstrate how to use the <code>abess</code> package to carry out best subset selection on the <code>Hitters</code> dataset. We hope to use several predictors related to the performance of the baseball athletes last year to predict their salary. First, letâ€™s have a look at this dataset. There are 19 variables except <code>Salary</code> and 322 observations.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Hitters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"Hitters.csv"</span>, header <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span></code></pre></div>
<pre><code>##   AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits CHmRun CRuns CRBI CWalks
## 1   293   66     1   30  29    14     1    293    66      1    30   29     14
## 2   315   81     7   24  38    39    14   3449   835     69   321  414    375
## 3   479  130    18   66  72    76     3   1624   457     63   224  266    263
## 4   496  141    20   65  78    37    11   5628  1575    225   828  838    354
## 5   321   87    10   39  42    30     2    396   101     12    48   46     33
## 6   594  169     4   74  51    35    11   4408  1133     19   501  336    194
##   League Division PutOuts Assists Errors Salary NewLeague
## 1      A        E     446      33     20     NA         A
## 2      N        W     632      43     10  475.0         N
## 3      A        W     880      82     14  480.0         A
## 4      N        E     200      11      3  500.0         N
## 5      N        E     805      40      4   91.5         N
## 6      A        W     282     421     25  750.0         A</code></pre>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 322  20</code></pre>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 59</code></pre>
<p>Note that this dataset contains some missing data. So we use the <code><a href="https://rdrr.io/r/stats/na.fail.html">na.omit()</a></code> function to delete rows that have incomplete information. After that, we have 263 observations remains.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Hitters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 263  20</code></pre>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>Then we change the factors into dummy variables with the <code><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix()</a></code> function. Note that the <code>abess</code> function will automatically include the intercept.</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">Hitters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="va">.</span>, <span class="va">Hitters</span><span class="op">)</span><span class="op">[</span>, <span class="op">-</span><span class="fl">1</span><span class="op">]</span>
<span class="va">Hitters</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/as.data.frame.html">as.data.frame</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span></code></pre></div>
</div>
<div id="running-abess" class="section level3">
<h3 class="hasAnchor">
<a href="#running-abess" class="anchor"></a>Running ABESS</h3>
<p>The <code><a href="../reference/abess.default.html">abess()</a></code> function in the <code>abess</code> package allows you to perform best subset selection in a highly efficient way. You can call the <code><a href="../reference/abess.default.html">abess()</a></code> function using formula just like what you do with <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>. Or you can specify the design matrix <code>x</code> and the response <code>y</code>. The <code>system.time</code> function records the run time.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/abess-team/abess">abess</a></span><span class="op">)</span>
<span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.default.html">abess</a></span><span class="op">(</span><span class="va">Salary</span> <span class="op">~</span> <span class="va">.</span>, <span class="va">Hitters</span><span class="op">)</span>
<span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.default.html">abess</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span> <span class="op">==</span> <span class="st">"Salary"</span><span class="op">)</span><span class="op">]</span>, <span class="va">Hitters</span><span class="op">$</span><span class="va">Salary</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] "abess"</code></pre>
</div>
<div id="interpret-the-result" class="section level3">
<h3 class="hasAnchor">
<a href="#interpret-the-result" class="anchor"></a>Interpret the Result</h3>
<p>After get the estimator, we can further do more exploring work. The output of <code><a href="../reference/abess.default.html">abess()</a></code> function contains the best model for all the candidate support size in the <code>support.size</code>. You can use some generic function to quickly draw some information of those estimators.</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># draw the estimated coefficients on all candidate support size</span>
<span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## 20 x 20 sparse Matrix of class "dgCMatrix"
##                                                                      
## (intercept) 535.9259 274.5803864 -47.9559022 -71.4592204   13.9231044
## AtBat         .        .           .           .            .        
## Hits          .        .           3.3008446   2.8038162    2.6757978
## HmRun         .        .           .           .            .        
## Runs          .        .           .           .            .        
## RBI           .        .           .           .            .        
## Walks         .        .           .           .            .        
## Years         .        .           .           .            .        
## CAtBat        .        .           .           .            .        
## CHits         .        .           .           .            .        
## CHmRun        .        .           .           .            .        
## CRuns         .        .           .           .            .        
## CRBI          .        0.7909536   0.6898994   0.6825275    0.6817790
## CWalks        .        .           .           .            .        
## LeagueN       .        .           .           .            .        
## DivisionW     .        .           .           .         -139.9538855
## PutOuts       .        .           .           0.2735814    0.2735002
## Assists       .        .           .           .            .        
## Errors        .        .           .           .            .        
## NewLeagueN    .        .           .           .            .        
##                                                                             
## (intercept)   -7.6563819   91.5117981   67.9431538  114.5067227  197.6616396
## AtBat          .           -1.8685892   -1.8535176   -2.1250564   -2.0803280
## Hits           2.0467293    7.6043976    7.6348879    7.6482495    6.8263359
## HmRun          .            .            .            .            .        
## Runs           .            .            .            .            .        
## RBI            .            .            .            .            .        
## Walks          2.5574106    3.6976468    3.6644212    5.2391412    5.9761215
## Years          .            .            .            .          -15.9414459
## CAtBat         .            .            .            .            .        
## CHits          .            .            .            .            .        
## CHmRun         .            .            .            .            .        
## CRuns          .            .            .            .            0.8143029
## CRBI           0.6492007    0.6430169    0.6445474    0.8959228    0.6000624
## CWalks         .            .            .           -0.3487728   -0.7503761
## LeagueN        .            .           35.0926551    .            .        
## DivisionW   -137.3676333 -122.9515338 -122.5437635 -126.8503150 -123.4936780
## PutOuts        0.2518721    0.2643076    0.2584749    0.2655057    0.2702288
## Assists        .            .            .            0.1790809    .        
## Errors         .            .            .            .            .        
## NewLeagueN     .            .            .            .            .        
##                                                                             
## (intercept)  206.5672285  218.5527334  198.4967427  142.9090129  144.6793182
## AtBat         -2.2556858   -2.2102483   -2.1783358   -2.0120568   -2.0883279
## Hits           7.0378766    6.9279436    6.9273744    7.3751935    7.6436454
## HmRun          .            .            .            .            2.3406524
## Runs           .            .            .           -1.7130320   -2.3580478
## RBI            .            .            .            .            .        
## Walks          6.2793246    6.2243570    6.1667822    5.9906173    6.1794713
## Years        -16.7414858  -17.2542087  -17.0664017    .            .        
## CAtBat         .            .            .           -0.1527096   -0.1488074
## CHits          .            .            .            .            .        
## CHmRun         .            .            .            .            .        
## CRuns          0.8132079    0.8111144    0.8082476    1.5535444    1.5931621
## CRBI           0.6508515    0.6594949    0.6571221    0.7850103    0.7170767
## CWalks        -0.7882990   -0.7934064   -0.7898841   -0.8404419   -0.8565844
## LeagueN        .            .           29.1474123   41.9165343   44.2352269
## DivisionW   -123.2261893 -123.1231837 -122.8009102 -112.3809790 -112.8079905
## PutOuts        0.2824819    0.2883338    0.2830813    0.2896964    0.2876182
## Assists        0.1872292    0.2795390    0.2732454    0.3312276    0.3677311
## Errors         .           -3.0198567   -3.3107203   -2.8685826   -3.1271251
## NewLeagueN     .            .            .            .            .        
##                                                                             
## (intercept)  163.3275824  163.0064063  162.9932027  163.1632541  163.1035878
## AtBat         -2.1085651   -2.0890552   -2.0302709   -2.0186239   -1.9798729
## Hits           7.6501026    7.8848050    7.7483580    7.7381465    7.5007675
## HmRun          2.3654025    3.8223369    4.6470956    4.6127592    4.3308829
## Runs          -2.3535049   -2.5377954   -2.5882384   -2.6272166   -2.3762100
## RBI            .           -0.8815425   -1.1165187   -1.1190038   -1.0449620
## Walks          6.1730276    6.2941910    6.2778803    6.3108843    6.2312863
## Years         -4.2321550   -4.0947594   -3.7490950   -3.8738277   -3.4890543
## CAtBat        -0.1341737   -0.1350897   -0.1526121   -0.1514014   -0.1713405
## CHits          .            .            .            .            0.1339910
## CHmRun         .            .           -0.3876922   -0.3938397   -0.1728611
## CRuns          1.5426322    1.5321626    1.5730263    1.5708067    1.4543049
## CRBI           0.7144063    0.7420886    0.8965235    0.8961782    0.8077088
## CWalks        -0.8446970   -0.8559654   -0.8423839   -0.8467366   -0.8115709
## LeagueN       42.2835360   42.2286763   41.6482699   61.3012822   62.5994230
## DivisionW   -113.9853363 -116.0422926 -116.4111439 -116.5862127 -116.8492456
## PutOuts        0.2859836    0.2858651    0.2827595    0.2829156    0.2818925
## Assists        0.3643305    0.3641325    0.3661464    0.3640952    0.3710692
## Errors        -3.2379385   -3.1409199   -3.1840695   -3.2558249   -3.3607605
## NewLeagueN     .            .            .          -22.9788245  -24.7623251</code></pre>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># get the deviance of the estimated model on all candidate support size</span>
<span class="fu"><a href="https://rdrr.io/r/stats/deviance.html">deviance</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span></code></pre></div>
<pre><code>##  [1] 202734.27 137565.32 116526.84 111214.06 106353.05 104483.91  99600.40
##  [8]  99303.92  98158.60  94654.62  94081.77  93894.74  93695.85  92354.17
## [15]  92200.23  92154.67  92106.59  92065.27  92032.81  92017.87</code></pre>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># print the fitted model</span>
<span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## Call:
## abess.default(x = Hitters[, -which(colnames(Hitters) == "Salary")], 
##     y = Hitters$Salary)
## 
##    support.size       dev      GIC
## 1             0 202734.27 3213.768
## 2             1 137565.32 3116.836
## 3             2 116526.84 3078.241
## 4             3 111214.06 3071.026
## 5             4 106353.05 3064.330
## 6             5 104483.91 3064.725
## 7             6  99600.40 3057.194
## 8             7  99303.92 3061.468
## 9             8  98158.60 3063.475
## 10            9  94654.62 3058.972
## 11           10  94081.77 3062.434
## 12           11  93894.74 3066.968
## 13           12  93695.85 3071.469
## 14           13  92354.17 3072.733
## 15           14  92200.23 3077.352
## 16           15  92154.67 3082.280
## 17           16  92106.59 3087.201
## 18           17  92065.27 3092.141
## 19           18  92032.81 3097.106
## 20           19  92017.87 3102.121</code></pre>
<p>Prediction is allowed for all the estimated model. Just call <code><a href="../reference/predict.abess.html">predict.abess()</a></code> function with the <code>support.size</code> set to the size of model you are interested in. If a <code>support.size</code> is not provided, prediction will be made on the model with best tuning value.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">hitters_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">abess_fit</span>, 
                        newx <span class="op">=</span> <span class="va">Hitters</span><span class="op">[</span>, <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">Hitters</span><span class="op">)</span> <span class="op">==</span> <span class="st">"Salary"</span><span class="op">)</span><span class="op">]</span>, 
                        support.size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">hitters_pred</span><span class="op">)</span></code></pre></div>
<pre><code>##           3         4
## 2 611.11976  545.8175
## 3 715.34087  643.8563
## 4 950.55323 1017.2414
## 5 424.10211  498.2470
## 6 708.86493  632.3839
## 7  59.21692  139.8497</code></pre>
<p>The <code><a href="../reference/plot.abess.html">plot.abess()</a></code> function helps to visualize the change of models with the change of support size. There are 5 types of graph you can generate, including <code>coef</code> for the coefficient value, <code>l2norm</code> for the L2-norm of the coefficients, <code>dev</code> for the deviance and <code>tune</code> for the tuning value. Default if <code>coef</code>.</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">abess_fit</span>, label <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<p><img src="v01-abess-guide_files/figure-html/unnamed-chunk-14-1.png" width="700"></p>
<p>The graph shows that, beginning from the most dense model, the 15th variable (Division, A factor with levels E and W indicating playerâ€™s division at the end of 1986) is included in the active set until the support size reaches 3.</p>
<p>We can also generate a graph about the tuning value. Remember that we used the default GIC to tune the support size.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">abess_fit</span>, type <span class="op">=</span> <span class="st">"tune"</span><span class="op">)</span></code></pre></div>
<p><img src="v01-abess-guide_files/figure-html/unnamed-chunk-15-1.png" width="700"></p>
<p>The tuning value reaches the lowest point at 6. And We might choose the estimated model with support size equals 6 as our final model. In fact, the tuning values of different model sizes are provided in <code>tune.value</code> of the <code>abess</code> object. You can get the best model size through the following call.</p>
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="../reference/extract.html">extract</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span><span class="op">[[</span><span class="st">"support.size"</span><span class="op">]</span><span class="op">]</span></code></pre></div>
<pre><code>## [1] 6</code></pre>
<p>To extract any model from the <code>abess</code> object, we can call the <code><a href="../reference/extract.html">extract()</a></code> function with a given <code>support.size</code>. If <code>support.size</code> is not provided, the model with the best tuning value will be returned. Here we extract the model with support size equals 6.</p>
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best.model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract.html">extract</a></span><span class="op">(</span><span class="va">abess_fit</span>, support.size <span class="op">=</span> <span class="fl">6</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">best.model</span><span class="op">)</span></code></pre></div>
<pre><code>## List of 7
##  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
##   .. ..@ i       : int [1:6] 0 1 5 11 14 15
##   .. ..@ p       : int [1:2] 0 6
##   .. ..@ Dim     : int [1:2] 19 1
##   .. ..@ Dimnames:List of 2
##   .. .. ..$ : chr [1:19] "AtBat" "Hits" "HmRun" "Runs" ...
##   .. .. ..$ : chr "6"
##   .. ..@ x       : num [1:6] -1.869 7.604 3.698 0.643 -122.952 ...
##   .. ..@ factors : list()
##  $ intercept   : num 91.5
##  $ support.size: num 6
##  $ support.vars: chr [1:6] "AtBat" "Hits" "Walks" "CRBI" ...
##  $ support.beta: num [1:6] -1.869 7.604 3.698 0.643 -122.952 ...
##  $ dev         : num 99600
##  $ tune.value  : num 3057</code></pre>
<p>The return is a list containing the basic information of the estimated model.</p>
</div>
</div>
<div id="advanced-features" class="section level2">
<h2 class="hasAnchor">
<a href="#advanced-features" class="anchor"></a>Advanced features</h2>
<div id="feature-screening-for-ultra-high-dimensional-dataset" class="section level3">
<h3 class="hasAnchor">
<a href="#feature-screening-for-ultra-high-dimensional-dataset" class="anchor"></a>Feature screening for ultra-high dimensional dataset</h3>
<p>The <a href="https://archive.ics.uci.edu/ml/datasets/communities+and+crime"></a> consists of 18 variables about crime from the 1995 FBI UCR (e.g., per capita arson crimes and per capita violent crimes), communities information in the U.S. (e.g., the percent of the population considered urban), socio-economic data from the 90s census (e.g., the median family income), and law enforcement data from the 1990 law enforcement management and admin stats survey (e.g., per capita number of police officers). It would be appropriate if any of the crime state in community can be modeled by the basic community information, socio-economic and law enforcement state in community. Here, without the loss of generality, per capita violent crimes is chosen as the response variable, and 102 numerical variables as well as their pairwise interactions is considered as predictors. <!-- Note that, the numerical variables with at least 50\% percentages missing observations are excluded,  --> <!-- and 200 observations without missing records are randomly picked out from the pool.  --> The pre-processed dataset for statistical modeling has 200 observations and 5253 predictors, and the code for pre-processing are openly shared in <a href="https://github.com/abess-team/abess/blob/master/R-package/data-raw/DATASET_VIGNETTES.R"></a>.<br>
The pre-processed dataset can be freely downloaded by running:</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">working_directory</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/getwd.html">getwd</a></span><span class="op">(</span><span class="op">)</span>
<span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/files.html">file.exists</a></span><span class="op">(</span><span class="st">"crime.rda"</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span>
  <span class="fu"><a href="https://rdrr.io/r/base/load.html">load</a></span><span class="op">(</span><span class="st">"crime.rda"</span><span class="op">)</span>
<span class="op">}</span> <span class="kw">else</span> <span class="op">{</span>
  <span class="va">crime_data_url</span> <span class="op">&lt;-</span> <span class="st">"https://github.com/abess-team/abess/raw/master/R-package/data-raw/crime.rda"</span>
  <span class="fu"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span><span class="op">(</span><span class="va">crime_data_url</span>, <span class="st">"crime.rda"</span><span class="op">)</span>
  <span class="fu"><a href="https://rdrr.io/r/base/load.html">load</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/file.path.html">file.path</a></span><span class="op">(</span><span class="va">working_directory</span>, <span class="st">"crime.rda"</span><span class="op">)</span><span class="op">)</span>
<span class="op">}</span></code></pre></div>
<p>As mentioned before, this dataset comprises 5000+ features, much larger than the number of observations:</p>
<div class="sourceCode" id="cb44"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">crime</span><span class="op">)</span></code></pre></div>
<pre><code>## [1]  500 5254</code></pre>
<p>And thus, it would be better to first perform feature screening, which is also supported by the <code>abess</code> function. Suppose we are interested in retaining 1000 variables with the largest marginal utility, then we can conduct the command:</p>
<div class="sourceCode" id="cb46"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.default.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">crime</span>, screening.num <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span></code></pre></div>
<pre><code>## List of 14
##  $ beta          :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
##   .. ..@ i       : int [1:528] 442 442 3950 442 3267 3950 442 1747 3267 3950 ...
##   .. ..@ p       : int [1:34] 0 0 1 3 6 10 15 21 28 36 ...
##   .. ..@ Dim     : int [1:2] 5253 33
##   .. ..@ Dimnames:List of 2
##   .. .. ..$ : chr [1:5253] "pop" "perHoush" "pctBlack" "pctWhite" ...
##   .. .. ..$ : chr [1:33] "0" "1" "2" "3" ...
##   .. ..@ x       : num [1:528] -0.251 -0.204 4.195 -0.161 0.527 ...
##   .. ..@ factors : list()
##  $ intercept     : num [1:33] 599 2115 1774 1270 1045 ...
##  $ dev           : num [1:33] 381863 172847 155975 147048 141513 ...
##  $ tune.value    : num [1:33] 6426 6043 6004 5987 5981 ...
##  $ nobs          : int 500
##  $ nvars         : int 5253
##  $ family        : chr "gaussian"
##  $ tune.path     : chr "sequence"
##  $ tune.type     : chr "GIC"
##  $ support.size  : int [1:33] 0 1 2 3 4 5 6 7 8 9 ...
##  $ edf           : num [1:33] 0 1 2 3 4 5 6 7 8 9 ...
##  $ best.size     : int 12
##  $ screening.vars: chr [1:1000] "pctBlack" "pctWhite" "medIncome" "pctWdiv" ...
##  $ call          : language abess.formula(formula = y ~ ., data = crime, screening.num = 1000)
##  - attr(*, "class")= chr "abess"</code></pre>
<p>The returned object of <code>abess</code> includes the features selected by screening. We exhibit six variables of them:</p>
<div class="sourceCode" id="cb48"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">[[</span><span class="st">"screening.vars"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] "pctBlack"     "pctWhite"     "medIncome"    "pctWdiv"      "pctPubAsst"  
## [6] "medFamIncome"</code></pre>
<p>Then, by the generic <code>extract</code> function, we can obtain the best model detected by <code>ABESS</code> algorithm, and get the variables in the best model:</p>
<div class="sourceCode" id="cb50"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/extract.html">extract</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="va">best_model</span><span class="op">)</span></code></pre></div>
<pre><code>## List of 7
##  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
##   .. ..@ i       : int [1:12] 303 331 368 405 1178 1747 2329 2603 3014 3267 ...
##   .. ..@ p       : int [1:2] 0 12
##   .. ..@ Dim     : int [1:2] 5253 1
##   .. ..@ Dimnames:List of 2
##   .. .. ..$ : chr [1:5253] "pop" "perHoush" "pctBlack" "pctWhite" ...
##   .. .. ..$ : chr "12"
##   .. ..@ x       : num [1:12] 0.336 -0.444 0.458 -0.134 0.196 ...
##   .. ..@ factors : list()
##  $ intercept   : num 706
##  $ support.size: int 12
##  $ support.vars: chr [1:12] "pctBlack:pctWhite" "pctBlack:pctCollGrad" "pctBlack:pctPopDenseHous" "pctWhite:pct12.1" ...
##  $ support.beta: num [1:12] 0.336 -0.444 0.458 -0.134 0.196 ...
##  $ dev         : num 111690
##  $ tune.value  : num 5963</code></pre>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">best_vars</span> <span class="op">&lt;-</span> <span class="va">best_model</span><span class="op">[[</span><span class="st">"support.vars"</span><span class="op">]</span><span class="op">]</span>
<span class="va">best_vars</span></code></pre></div>
<pre><code>##  [1] "pctBlack:pctWhite"                   
##  [2] "pctBlack:pctCollGrad"                
##  [3] "pctBlack:pctPopDenseHous"            
##  [4] "pctWhite:pct12.1"                    
##  [5] "pctUrban:pctUnemploy"                
##  [6] "pctPubAsst:ownHousQrange"            
##  [7] "otherPerCap:pctPoverty"              
##  [8] "pctPoverty:ownHousMed"               
##  [9] "pctEmployMfg:pctVacantBoarded"       
## [10] "pctMaleDivorc:pctSmallHousUnits"     
## [11] "pctKids:medOwnCostPctWO"             
## [12] "pctKidsBornNevrMarr:pctVacantBoarded"</code></pre>
<!-- From the linear model based on the selected features, we see that the two predictors,  -->
<!-- 'pctMaleDivorc:pctKidsBornNevrMarr'  -->
<!-- (i.e., the linear interaction between the percentage of divorced males and the percentage of kids born to never married)  -->
<!-- and 'pct65up:pctPopDenseHous'  -->
<!-- (i.e., the linear interaction between the percentage of population that is 65 at least in age and the percent of persons in dense housing that have more than 1 person per room), have the most significant impact on the response:  -->
<!-- We visualize the relationship between the response and the  -->
<!-- two most significant -->
<!-- selected predictors: -->
<!-- ![](./crime.jpg) -->
</div>
<div id="more-features" class="section level3">
<h3 class="hasAnchor">
<a href="#more-features" class="anchor"></a>More features</h3>
<p>There are plenty features provided by <code>abess</code> packages such as logistic regression and group selection. Please the other articles in our website for more details.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Jin Zhu, Kangkang Jiang, Yanhang Zhang, Liyuan Hu, Junhao Huang, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
